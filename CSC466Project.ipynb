{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CSC466Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNzwlzxoV-Hp"
      },
      "source": [
        "#@title Data\n",
        "intents = {\n",
        "    \"intents\": [\n",
        "                {\n",
        "                    \"tag\": \"greeting\",\n",
        "                    \"patterns\": [\"Hello\", \"Hey\", \"Hi\", \"How's it going\", \"Hello there\", \"Hi there\", \"Greetings\"],\n",
        "                    \"responses\": [\"How are you?\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"doing_good\",\n",
        "                    \"patterns\": [\"I'm doing good\", \"good\", \"I'm doing well\", \"I'm doing great\", \"I'm good\", \"I'm great\"],\n",
        "                    \"responses\": [\"Great! How can I help you?\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"doing_bad\",\n",
        "                    \"patterns\": [\"I'm doing bad\", \"I'm bad\", \"not good\", \"not too great\", \"not well\", \"bad\"],\n",
        "                    \"responses\": [\"Sorry to hear that. Anything I can help you with?\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"goodbye\",\n",
        "                    \"patterns\": [\"Goodbye\", \"Have a good one!\", \"See you soon\", \"It was great talking to you, bye bye!\"],\n",
        "                    \"responses\": [\"Bye\", \"Thanks for coming in\", \"See you\", \"Have a nice day!\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"thanks\",\n",
        "                    \"patterns\": [\"Thank you so much!\", \"Thanks\", \"Thank you\", \"Cool, thanks!\", \"Wow, that was so helpful!\", \"Thanks for the help!\"],\n",
        "                    \"responses\": [\"No problem\", \"Any time\", \"Happy to help\", \"Absolutely\", \"You're very welcome\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"complete\",\n",
        "                    \"patterns\": [\"Alright, that's all I need\", \"That is all I have\"],\n",
        "                    \"responses\": [\"Great, if you have any more questions about prerequisites or course recommendations, just ask!\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"noanswer\",\n",
        "                    \"patterns\": [\"\"],\n",
        "                    \"responses\": [\"Sorry, I couldn't understand that\", \"Can you please provide a bit more information?\", \"I'm not sure what you mean?\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"prereqs\",\n",
        "                    \"patterns\": [\"I need to find the prereqs for some classes\", \"Can you tell me what the prerequisites are for a course?\"],\n",
        "                    \"responses\": [\"Just type in the CSC followed by the course number and I'll let you know what the prereqs are\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"recommendations\",\n",
        "                    \"patterns\": [\"I need help deciding on what CSC classes to take next quarter\", \"Can you help me pick some courses for next quarter?\", \"I need some recommendations for what classes to take next quarter.\"],\n",
        "                    \"responses\": [\"Sure, just let me know what year/class standing you'll be and what quarter you need the recommendation for.\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"options\",\n",
        "                    \"patterns\": [\"What do you do?\", \"How can you help me?\", \"What information do you have?\"],\n",
        "                    \"responses\": [\"Based on some of your degree progress information, I can help suggest some Computer Science courses for you to take this coming quarter. Or if you need to know the prerequisites for a CSC course, just say the course number.\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"info_gain\",\n",
        "                    \"patterns\": [\"What types of information do you need from me?\", \"What do you need from me?\", \"How do we get started?\"],\n",
        "                    \"responses\": [\"To get started, please give me your class standing and what quarter you need suggestions for.\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"freshmen_fall\",\n",
        "                    \"patterns\": [\"I am a Freshmen and I need help planning for Fall quarter\", \"I'm a first year and I need advice planning for Fall quarter\"],\n",
        "                    \"responses\": [\"It is suggested that you take CSC 123 this coming Fall quarter\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"freshmen_winter\",\n",
        "                    \"patterns\": [\"I am a Freshmen and I need help planning for Winter quarter\", \"I'm a first year and I need advice planning for Winter quarter\"],\n",
        "                    \"responses\": [\"If you haven't already recieved transfer credit or AP credit for it, it is suggested that you take CSC 101 this coming Winter quarter\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"freshmen_spring\",\n",
        "                    \"patterns\": [\"I am a Freshmen and I need help planning for Spring quarter\", \"I'm a first year and I need advice planning for Spring quarter\"],\n",
        "                    \"responses\": [\"As long as you have completed CSC 101 and MATH 141 or 221, it is suggested that you take CSC 202 this coming Spring quarter\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"sophomore_fall\",\n",
        "                    \"patterns\": [\"I am a Sophomore and I need help planning for Fall quarter\", \"I'm a second year and I need advice planning for Fall quarter\"],\n",
        "                    \"responses\": [\"As long as you have completed CSC 202, it is suggested that you take CSC 203 and/or CSC 225 this coming Fall quarter\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"sophomore_winter/spring\",\n",
        "                    \"patterns\": [\"I am a Sophomore and I need help planning for Winter quarter\", \"I'm a second year and I need advice planning for Winter quarter\", \n",
        "                                 \"I am a Sophomore and I need help planning for Spring quarter\", \"I'm a second year and I need advice planning for Spring quarter\"],\n",
        "                    \"responses\": [\"As long as you have completed CSC 202 and CSC 203, some good classes for you to take are CSC 348, CSC 315, and/ or CSC 357\",\n",
        "                                  \"If you haven't already, it is suggested that you take CSC 225\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"junior_fall\",\n",
        "                    \"patterns\": [\"I am a Junior and I need help planning for Fall quarter\", \"I'm a third year and I need advice planning for Fall quarter\"],\n",
        "                    \"responses\": [\"As long as you have completed CSC 202 and 203, along with CSC 348, it is suggested that you take CSC 349 this coming Fall quarter\",\n",
        "                                  \"It is suggested that you begin one of two software engineering series this fall, starting with either CSC 307 or CSC 308\",\n",
        "                                  \"If you haven't already, a good class to take is CSC 315\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"junior_winter\",\n",
        "                    \"patterns\": [\"I am a Junior and I need help planning for Winter quarter\", \"I'm a third year and I need advice planning for Winter quarter\"],\n",
        "                    \"responses\": [\"If you haven't completed it already, it is suggested that you complete the second part of your series on Software engineering, taking either a Tech elective or CPE 309, depending on which part of the series you chose\",\n",
        "                                  \"As long as you have completed CSC 349 and CSC 357, it is suggested that you take CSC 430 this coming quarter\",\n",
        "                                  \"If you haven't already, a few good classes to take are CSC 315, CSC 300, and CSC 453\",\n",
        "                                  \"It is suggested that you take one of the approved technical electives\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"junior_winter\",\n",
        "                    \"patterns\": [\"I am a Junior and I need help planning for Spring quarter\", \"I'm a third year and I need advice planning for Spring quarter\"],\n",
        "                    \"responses\": [\"As long as you have completed CSC 430, it is suggested that you take CSC 431 this coming quarter\",\n",
        "                                  \"If you haven't already, a few good classes to take are CSC 315, CSC 300, and CSC 453\",\n",
        "                                  \"It is suggested that you take one of the approved technical electives\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"senior_fall\",\n",
        "                    \"patterns\": [\"I am a Senior and I need help planning for Fall quarter\", \"I'm a fourth year and I need advice planning for Fall quarter\"],\n",
        "                    \"responses\": [\"As long as you have completed CSC 141 or CSC 348, it is suggested that you take CSC 445 this coming quarter\",\n",
        "                                  \"If you haven't already, a few good classes to take are CSC 300, and CSC 453\",\n",
        "                                  \"It is suggested that you take one of the approved technical electives\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"senior_winter\",\n",
        "                    \"patterns\": [\"I am a Senior and I need help planning for Winter quarter\", \"I'm a fourth year and I need advice planning for Winter quarter\"],\n",
        "                    \"responses\": [\"As long as you have completed CSC 307 or CSC 309, it is suggested that you take CSC 491 this coming quarter\",\n",
        "                                  \"If you haven't already, a few good classes to take are CSC 300, and CSC 453\",\n",
        "                                  \"It is suggested that you take a couple of the approved technical electives\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"senior_spring\",\n",
        "                    \"patterns\": [\"I am a Senior and I need help planning for Spring quarter\", \"I'm a fourth year and I need advice planning for Spring quarter\"],\n",
        "                    \"responses\": [\"As long as you completed CSC 491 last quarter, it is suggested that you take CSC 492 this coming quarter\",\n",
        "                                  \"If you haven't already, a few good classes to take are CSC 300, and CSC 453\",\n",
        "                                  \"If you have yet to fullfill the requirements on technical elective courses, it is suggested that you take a couple of the approved technical electives. Take a look at the Cal Poly CSC website for more information on approved electives\"], # wording\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"technical_electives\",\n",
        "                    \"patterns\": [\"What technical electives should I take?\", \"What elective classes are good to take?\"],\n",
        "                    \"responses\": [\"The suggested technical electives depend on your concentration and your interests (Ex. Software engineering, game design, etc.). What is your concentration? If it is the general curriculum, also specify some of your interests.\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"general_software\",\n",
        "                    \"patterns\": [\"General Curriculum, Software Engineering\"],\n",
        "                    \"responses\": [\"Some good electives in Software design/engineering for the general curriculum concentration are CSC 305, 309, 402, 405, 409\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"general_security\",\n",
        "                    \"patterns\": [\"General Curriculum, Security, privacy\"],\n",
        "                    \"responses\": [\"Some good electives in security/privacy for the general curriculum concentration are CSC 321, 323, 325, 422, 424, 425, 429, 521, 524, CPE 464\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"general_game\",\n",
        "                    \"patterns\": [\"General Curriculum, Game design, gaming\"],\n",
        "                    \"responses\": [\"Some good electives in game development for the general curriculum concentration are CSC 371, 377, 378, 471, 473, 474, 476, 478, 480\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"ai_ml\",\n",
        "                    \"patterns\": [\"Artificial Intelligence and Machine Learning concentration\", \"Artificial Intelligence\", \"Machine Learning\", \"AI\", \"ML\"],\n",
        "                    \"responses\": [\"The following technical electives are required as a part of the AI and machine learning concentration: CSC 365 (or DATA 301), 466, 480, 487, and STAT 334. 8 more units of any of the following are also required: CPE 428, CSC 481, 482, 566, 580, 581, 582, EE 509, STAT 434\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"data_engineering\",\n",
        "                    \"patterns\": [\"Data Engineering\", \"Data Engineering Concentration\"],\n",
        "                    \"responses\": [\"The following technical electives are required as a part of the data engineering concentration: CSC 365, 366, 436 (or 437 or 309), 466, 468 (or 469). 4 more units of any of the following are also required: CPE/EE 428, CSC 369, 400, 468, 469, 480, 482, 487, 560, 566, 569\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"game_dev\",\n",
        "                    \"patterns\": [\"Game Development\", \"Game Development Concentration\"],\n",
        "                    \"responses\": [\"The following technical electives are required as a part of the game development concentration: COMS 404, CSC 371, 377, 378, ISLA 340. 4 more units of any of the following are also required: ART 182, 183, 376, 384, CSC 309, 471, 473, 474, 476, 478, 480, ISLA 240, 341, 387, 411, 412\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"priv_sec\",\n",
        "                    \"patterns\": [\"Privacy\", \"Security\", \"Privacy and Security Concentration\"],\n",
        "                    \"responses\": [\"CPE 464 is required as part of the Privacy and Security Concentration. 12 more units from the following are also required: CPE 422, 426, CSC 323, 325, 424, 425, 429, 521, 524. Finally, 8 units from any of the following are also required: CPE 422, 426, 431, 454, 465, CSC 323, 325, 400, 424, 425, 429, 521, 524, MATH 341, 437, 451, 453, 481\"],\n",
        "                    \"context\": [\"\"] \n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"graphics_gpu\",\n",
        "                    \"patterns\": [\"Graphics concentration\", \"graphics\", \"GPU/Systems Track\", \"GPU\", \"Systems\"],\n",
        "                    \"responses\": [\"The following are required as a part of the Graphics concentration: CSE 471, 473, 474, 476, 572. For the GPU/Systems track one of CSC 473, 474, 476, or 572 are also required. 8 units of any other technical elective is also required\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"graphics_art\",\n",
        "                    \"patterns\": [\"Graphics concentration\", \"graphic arts\", \"Art Track\"],\n",
        "                    \"responses\": [\"The following are required as a part of the Grpahics concentration: CSE 471, 473, 474, 476, 572. For the Art track one of CSC 350 & 450 or ART 376 or 384 are also required. One of CSC 371, 377, & 378 are also required. Finally, 4 units of any technical elective is also required\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"appr_math_prereq\",\n",
        "                    \"patterns\": [\"CSC 101\", \"CSC 121\"],\n",
        "                    \"responses\": [\"Prerequisite requirements for this course include: an Appropriate Math Placement Level.\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc122\",\n",
        "                    \"patterns\": [\"CSC 122\"],\n",
        "                    \"responses\": [\"Prerequisite requirements for this course include: CSC 121\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc123\",\n",
        "                    \"patterns\": [\"CSC 122\"],\n",
        "                    \"responses\": [\"Prerequisite requirements for this course include: Basic computer literacy\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc200\",\n",
        "                    \"patterns\": [\"CSC 200\"],\n",
        "                    \"responses\": [\"Prerequisite requirements for this course include: Consent of the instructor\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc202\",\n",
        "                    \"patterns\": [\"CSC 202\"],\n",
        "                    \"responses\": [\"Prerequisite requirements for this course include: CPE/CSC 101, MATH 141 or MATH 221, or consent of the instructor\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc202_prereq\",\n",
        "                    \"patterns\": [\"CSC 203\", \"CSC 225\", \"CSC 313\", \"CSC 377\"],\n",
        "                    \"responses\": [\"Prerequisite requirements for this course include: CSC 202\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc248\",\n",
        "                    \"patterns\": [\"CSC 248\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 202, 203\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc290\",\n",
        "                    \"patterns\": [\"CSC 290\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: Open to undergraduate students and consent of instructor\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc300\",\n",
        "                    \"patterns\": [\"CSC 300\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: Completion of GE Area A3, CSC 357 and Junior Standing\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc357_prereq\",\n",
        "                    \"patterns\": [\"CSC 305\", \"CSC 321\", \"CSC 323\", \"CSC 436\", \"CSC 458\", \"CSC 469\", \"CSC 471\", \"CSC 524\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 357\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc248_348_357_prereq\",\n",
        "                    \"patterns\": [\"CSC 307\", \"CSC 344\", \"CSC 569\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 248 or CSC 348 and CSC 357\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"248/348_prereq\",\n",
        "                    \"patterns\": [\"CSC 308\", \"CSC 445\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 248 or 348\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc309\",\n",
        "                    \"patterns\": [\"CSC 309\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 308 and CSC 357\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc325\",\n",
        "                    \"patterns\": [\"CSC 325\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: Completion of GE Area A3, CSC 203, 300 or PHIL 323\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"102/103_202/203_248_prereq\",\n",
        "                    \"patterns\": [\"CSC 349\", \"CSC365\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 102 and 103 OR CSC 202 and 203; MATH 142 and CSC 248, 348 OR MATH 248\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc350\",\n",
        "                    \"patterns\": [\"CSC 350\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: ART 384; CSC 103 or 202 and Junior Standing\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc357\",\n",
        "                    \"patterns\": [\"CSC 357\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 102, 103 or CSC 202, 203; and CSC 225 or CPE/EE 229 or CPE/EE 233\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc365_prereq\",\n",
        "                    \"patterns\": [\"CSC 366\", \"CSC 468\", \"CSC 560\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 365\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc369\",\n",
        "                    \"patterns\": [\"CSC 369\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 102 and 103 OR CSC 202 and 203; and one of the following STAT 301, 312, 321, 350\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"102/103_202js_prereq\",\n",
        "                    \"patterns\": [\"CSC 371\", \"CSC 378\", \"CSC 480\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 102 and 103 or CSC 202 and Junior Standing\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"consentofinstructor_prereq\",\n",
        "                    \"patterns\": [\"CSC 400\", \"CSC 490\", \"CSC 493\", \"CSC 494\", \"CSC 495\", \"CSC 496\", \"CSC 500\", \"CSC 590\", \"CSC 593\", \"CSC 594\", \"CSC 595\", \"CSC 596\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: Consent of the instructor\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc307/309_prereq\",\n",
        "                    \"patterns\": [\"CSC 402\", \"CSC 409\", \"CSC 491\", \"CSC 497\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 307 or CSC 309\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc405\",\n",
        "                    \"patterns\": [\"CSC 405\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 305 and CSC 402\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc406\",\n",
        "                    \"patterns\": [\"CSC 406\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 405\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"349_STATelec_prereq\",\n",
        "                    \"patterns\": [\"CSC 410\", \"CSC 466\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 349; STAT 301, 312, 321 or 350\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"cpe464_prereq\",\n",
        "                    \"patterns\": [\"CSC 422\", \"CSC 564\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CPE 464\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc424\",\n",
        "                    \"patterns\": [\"CSC 424\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 307 or 309; CPE/CSC 321\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc425\",\n",
        "                    \"patterns\": [\"CSC 425\", \"CSC 521\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 321\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc429\",\n",
        "                    \"patterns\": [\"CSC 429\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 321 and 357\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc430\",\n",
        "                    \"patterns\": [\"CSC 430\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 349 and 357\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc430_prereq\",\n",
        "                    \"patterns\": [\"CSC 431\", \"CSC 530\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 430\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc437\",\n",
        "                    \"patterns\": [\"CSC 437\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 357 and CSC 365\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"349_prereq\",\n",
        "                    \"patterns\": [\"CSC 448\", \"CSC 477\", \"CSC 549\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 349\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc450\",\n",
        "                    \"patterns\": [\"CSC 450\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 350\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc453\",\n",
        "                    \"patterns\": [\"CSC 453\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 357, 225, CPE/EE 229 or 233\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc453_prereq\",\n",
        "                    \"patterns\": [\"CSC 454\", \"CSC 550\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 453\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc471_prereq\",\n",
        "                    \"patterns\": [\"CSC 473\", \"CSC 474\", \"CSC 476\", \"CSC 478\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 471\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc480_prereq\",\n",
        "                    \"patterns\": [\"CSC 481\", \"CSC 580\", \"CSC 581\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 480\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc482\",\n",
        "                    \"patterns\": [\"CSC 482\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 466 or 480\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc307/308_prereq\",\n",
        "                    \"patterns\": [\"CSC 484\", \"CSC 486\", \"CSC 508\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 307 or CSC 308\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc487\",\n",
        "                    \"patterns\": [\"CSC 487\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 349 and MATH 206 or 244\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc492\",\n",
        "                    \"patterns\": [\"CSC 492\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 491\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc498\",\n",
        "                    \"patterns\": [\"CSC 498\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 497\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc509\",\n",
        "                    \"patterns\": [\"CSC 509\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 508\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc515\",\n",
        "                    \"patterns\": [\"CSC 515\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CPE 315 or 333\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc540\",\n",
        "                    \"patterns\": [\"CSC 540\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 445\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc566\",\n",
        "                    \"patterns\": [\"CSC 566\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 466 or 480 or 582\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc570\",\n",
        "                    \"patterns\": [\"CSC 570\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: Graduate standing and evidence of satisfactory preparation in computer science\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc572\",\n",
        "                    \"patterns\": [\"CSC 572\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 471\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc582\",\n",
        "                    \"patterns\": [\"CSC 582\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 482\"],\n",
        "                    \"context\": [\"\"]\n",
        "                },\n",
        "                {\n",
        "                    \"tag\": \"csc599\",\n",
        "                    \"patterns\": [\"CSC 599\"],\n",
        "                    \"responses\": [\"Prequisite requirements for this course include: CSC 590; CSC 498 or 597\"],\n",
        "                    \"context\": [\"\"]\n",
        "                }\n",
        "    ]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zw9iBY_aWKK"
      },
      "source": [
        "Access the code for the dataset by right clicking the chunk, then go to \"Form,\" then \"Show code.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlDnkz6uajq4"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h0u0E_vbYnj",
        "cellView": "form",
        "outputId": "5d05dd47-47ee-4dd0-82c2-5ae689bd8c03"
      },
      "source": [
        "#@title Packages\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "tknzr = TweetTokenizer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rptj2cy_ZdAy"
      },
      "source": [
        "classes = []\n",
        "documents = []\n",
        "patterns = []\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "      patterns.append(pattern)\n",
        "      \n",
        "      documents.append((tknzr.tokenize(pattern), intent['tag']))\n",
        "\n",
        "      if intent['tag'] not in classes:\n",
        "          classes.append(intent['tag'])\n",
        "classes = sorted(list(set(classes)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ow_aUaQFujv"
      },
      "source": [
        "unigram_vec = CountVectorizer()\n",
        "bigram_vec = CountVectorizer(ngram_range=(2, 2))\n",
        "trigram_vec = CountVectorizer(ngram_range=(3, 3))\n",
        "\n",
        "unigram_vec.fit(patterns)\n",
        "bigram_vec.fit(patterns)\n",
        "trigram_vec.fit(patterns)\n",
        "\n",
        "X_train_unigram = unigram_vec.transform(patterns)\n",
        "X_train_bigram = bigram_vec.transform(patterns)\n",
        "X_train_trigram = trigram_vec.transform(patterns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAIj_wp2U02X"
      },
      "source": [
        "train_y = []\n",
        "output_empty = [0] * len(classes)\n",
        "for doc in documents:\n",
        "  output_row = list(output_empty)\n",
        "  output_row[classes.index(doc[1])] = 1\n",
        "  train_y.append(output_row)\n",
        "y_train = np.array(train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL0T71JHKhTA"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byr2BDdVHesd",
        "outputId": "636cab6d-8fb9-47e7-a993-5b475d917c54"
      },
      "source": [
        "def train_model(X_train, y_train):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, input_shape=(np.shape(X_train)[1],), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(np.shape(y_train)[1], activation='softmax'))\n",
        "\n",
        "  sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  hist = model.fit(X_train.toarray(), np.array(y_train), epochs=200, batch_size=5, verbose=1)\n",
        "\n",
        "  return model\n",
        "\n",
        "unigram_model = train_model(X_train_unigram, y_train)\n",
        "bigram_model = train_model(X_train_bigram, y_train)\n",
        "trigram_model = train_model(X_train_trigram, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "38/38 [==============================] - 14s 2ms/step - loss: 4.4038 - accuracy: 0.0169\n",
            "Epoch 2/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.3599 - accuracy: 0.0535\n",
            "Epoch 3/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.2796 - accuracy: 0.0975\n",
            "Epoch 4/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.1509 - accuracy: 0.0813\n",
            "Epoch 5/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.1187 - accuracy: 0.0786\n",
            "Epoch 6/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.9986 - accuracy: 0.1057\n",
            "Epoch 7/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.8952 - accuracy: 0.1037\n",
            "Epoch 8/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.7757 - accuracy: 0.1358\n",
            "Epoch 9/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.6411 - accuracy: 0.1616\n",
            "Epoch 10/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.5030 - accuracy: 0.2271\n",
            "Epoch 11/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.4011 - accuracy: 0.1662\n",
            "Epoch 12/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.3297 - accuracy: 0.2522\n",
            "Epoch 13/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1877 - accuracy: 0.2044\n",
            "Epoch 14/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2378 - accuracy: 0.2204\n",
            "Epoch 15/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1734 - accuracy: 0.2040\n",
            "Epoch 16/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2710 - accuracy: 0.1925\n",
            "Epoch 17/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0576 - accuracy: 0.2256\n",
            "Epoch 18/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0328 - accuracy: 0.2307\n",
            "Epoch 19/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9320 - accuracy: 0.1981\n",
            "Epoch 20/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7805 - accuracy: 0.2482\n",
            "Epoch 21/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7690 - accuracy: 0.3146\n",
            "Epoch 22/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6477 - accuracy: 0.3308\n",
            "Epoch 23/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8747 - accuracy: 0.2510\n",
            "Epoch 24/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6532 - accuracy: 0.3151\n",
            "Epoch 25/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.5729 - accuracy: 0.3765\n",
            "Epoch 26/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4945 - accuracy: 0.3553\n",
            "Epoch 27/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4546 - accuracy: 0.3749\n",
            "Epoch 28/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4088 - accuracy: 0.3781\n",
            "Epoch 29/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4234 - accuracy: 0.3656\n",
            "Epoch 30/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4919 - accuracy: 0.3423\n",
            "Epoch 31/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.2200 - accuracy: 0.4635\n",
            "Epoch 32/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.3925 - accuracy: 0.3751\n",
            "Epoch 33/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1310 - accuracy: 0.4446\n",
            "Epoch 34/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.2291 - accuracy: 0.4302\n",
            "Epoch 35/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1880 - accuracy: 0.4341\n",
            "Epoch 36/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.0409 - accuracy: 0.4059\n",
            "Epoch 37/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9994 - accuracy: 0.4637\n",
            "Epoch 38/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.0328 - accuracy: 0.4491\n",
            "Epoch 39/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.8707 - accuracy: 0.5351\n",
            "Epoch 40/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9769 - accuracy: 0.4564\n",
            "Epoch 41/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9090 - accuracy: 0.4905\n",
            "Epoch 42/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.8147 - accuracy: 0.5326\n",
            "Epoch 43/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7212 - accuracy: 0.5409\n",
            "Epoch 44/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.6558 - accuracy: 0.5405\n",
            "Epoch 45/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7263 - accuracy: 0.5541\n",
            "Epoch 46/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7055 - accuracy: 0.5847\n",
            "Epoch 47/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3624 - accuracy: 0.6126\n",
            "Epoch 48/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7086 - accuracy: 0.5600\n",
            "Epoch 49/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4300 - accuracy: 0.6179\n",
            "Epoch 50/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4516 - accuracy: 0.6097\n",
            "Epoch 51/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5397 - accuracy: 0.5888\n",
            "Epoch 52/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3590 - accuracy: 0.6174\n",
            "Epoch 53/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4464 - accuracy: 0.6463\n",
            "Epoch 54/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3560 - accuracy: 0.6363\n",
            "Epoch 55/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5323 - accuracy: 0.5923\n",
            "Epoch 56/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4536 - accuracy: 0.5706\n",
            "Epoch 57/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5060 - accuracy: 0.5767\n",
            "Epoch 58/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2283 - accuracy: 0.6739\n",
            "Epoch 59/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2608 - accuracy: 0.6452\n",
            "Epoch 60/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3215 - accuracy: 0.6478\n",
            "Epoch 61/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2146 - accuracy: 0.6658\n",
            "Epoch 62/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0707 - accuracy: 0.7314\n",
            "Epoch 63/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3202 - accuracy: 0.6283\n",
            "Epoch 64/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2892 - accuracy: 0.6774\n",
            "Epoch 65/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1127 - accuracy: 0.7238\n",
            "Epoch 66/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1342 - accuracy: 0.6960\n",
            "Epoch 67/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1459 - accuracy: 0.7211\n",
            "Epoch 68/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0488 - accuracy: 0.6696\n",
            "Epoch 69/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8401 - accuracy: 0.7933\n",
            "Epoch 70/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0721 - accuracy: 0.7243\n",
            "Epoch 71/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0468 - accuracy: 0.6870\n",
            "Epoch 72/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0823 - accuracy: 0.7016\n",
            "Epoch 73/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8738 - accuracy: 0.7205\n",
            "Epoch 74/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9449 - accuracy: 0.7361\n",
            "Epoch 75/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.7051\n",
            "Epoch 76/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7983 - accuracy: 0.8082\n",
            "Epoch 77/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0305 - accuracy: 0.6922\n",
            "Epoch 78/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0033 - accuracy: 0.7470\n",
            "Epoch 79/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8395 - accuracy: 0.7511\n",
            "Epoch 80/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8350 - accuracy: 0.7327\n",
            "Epoch 81/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0014 - accuracy: 0.7349\n",
            "Epoch 82/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8686 - accuracy: 0.7826\n",
            "Epoch 83/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9419 - accuracy: 0.7255\n",
            "Epoch 84/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9655 - accuracy: 0.7402\n",
            "Epoch 85/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.7804\n",
            "Epoch 86/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8571 - accuracy: 0.7772\n",
            "Epoch 87/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7696 - accuracy: 0.8187\n",
            "Epoch 88/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7808 - accuracy: 0.7727\n",
            "Epoch 89/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.8442\n",
            "Epoch 90/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7067 - accuracy: 0.7913\n",
            "Epoch 91/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7591 - accuracy: 0.7692\n",
            "Epoch 92/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8628 - accuracy: 0.7450\n",
            "Epoch 93/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.8381\n",
            "Epoch 94/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.8013\n",
            "Epoch 95/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.8461\n",
            "Epoch 96/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.8585\n",
            "Epoch 97/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.7857\n",
            "Epoch 98/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.7786\n",
            "Epoch 99/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7679 - accuracy: 0.7728\n",
            "Epoch 100/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.8208\n",
            "Epoch 101/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7567 - accuracy: 0.7944\n",
            "Epoch 102/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8364 - accuracy: 0.7607\n",
            "Epoch 103/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.7576\n",
            "Epoch 104/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.7926\n",
            "Epoch 105/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.8256\n",
            "Epoch 106/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7680 - accuracy: 0.7475\n",
            "Epoch 107/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7241 - accuracy: 0.7753\n",
            "Epoch 108/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.8453\n",
            "Epoch 109/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.8283\n",
            "Epoch 110/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.8523\n",
            "Epoch 111/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8898\n",
            "Epoch 112/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.8265\n",
            "Epoch 113/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8070 - accuracy: 0.7505\n",
            "Epoch 114/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.8054\n",
            "Epoch 115/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.7803\n",
            "Epoch 116/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.8038\n",
            "Epoch 117/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8572\n",
            "Epoch 118/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7767\n",
            "Epoch 119/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.7654\n",
            "Epoch 120/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8539\n",
            "Epoch 121/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.8518\n",
            "Epoch 122/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8380\n",
            "Epoch 123/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.7871\n",
            "Epoch 124/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8848\n",
            "Epoch 125/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.8158\n",
            "Epoch 126/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8599\n",
            "Epoch 127/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8604\n",
            "Epoch 128/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8829\n",
            "Epoch 129/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.8511\n",
            "Epoch 130/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8989\n",
            "Epoch 131/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8685\n",
            "Epoch 132/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8319\n",
            "Epoch 133/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.8094\n",
            "Epoch 134/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8532\n",
            "Epoch 135/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.7685\n",
            "Epoch 136/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7766\n",
            "Epoch 137/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8355\n",
            "Epoch 138/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.8037\n",
            "Epoch 139/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.8518\n",
            "Epoch 140/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.8191\n",
            "Epoch 141/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8780\n",
            "Epoch 142/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8525\n",
            "Epoch 143/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7897\n",
            "Epoch 144/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8750\n",
            "Epoch 145/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8695\n",
            "Epoch 146/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8297\n",
            "Epoch 147/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.8162\n",
            "Epoch 148/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8678\n",
            "Epoch 149/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.9115\n",
            "Epoch 150/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8369\n",
            "Epoch 151/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8623\n",
            "Epoch 152/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.9150\n",
            "Epoch 153/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8931\n",
            "Epoch 154/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.8216\n",
            "Epoch 155/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8657\n",
            "Epoch 156/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8727\n",
            "Epoch 157/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.9223\n",
            "Epoch 158/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8489\n",
            "Epoch 159/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8440\n",
            "Epoch 160/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.9264\n",
            "Epoch 161/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.8464\n",
            "Epoch 162/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8901\n",
            "Epoch 163/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8743\n",
            "Epoch 164/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.8341\n",
            "Epoch 165/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.8552\n",
            "Epoch 166/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8289\n",
            "Epoch 167/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8886\n",
            "Epoch 168/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.8132\n",
            "Epoch 169/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8751\n",
            "Epoch 170/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8540\n",
            "Epoch 171/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.8259\n",
            "Epoch 172/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8562\n",
            "Epoch 173/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7967\n",
            "Epoch 174/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8710\n",
            "Epoch 175/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8672\n",
            "Epoch 176/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8802\n",
            "Epoch 177/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.9118\n",
            "Epoch 178/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.8134\n",
            "Epoch 179/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8590\n",
            "Epoch 180/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.7783\n",
            "Epoch 181/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.8397\n",
            "Epoch 182/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7977\n",
            "Epoch 183/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8761\n",
            "Epoch 184/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8566\n",
            "Epoch 185/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8677\n",
            "Epoch 186/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7841\n",
            "Epoch 187/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8587\n",
            "Epoch 188/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8908\n",
            "Epoch 189/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.8089\n",
            "Epoch 190/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8761\n",
            "Epoch 191/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8557\n",
            "Epoch 192/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.9073\n",
            "Epoch 193/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8751\n",
            "Epoch 194/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8673\n",
            "Epoch 195/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8892\n",
            "Epoch 196/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8830\n",
            "Epoch 197/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.9064\n",
            "Epoch 198/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8586\n",
            "Epoch 199/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8651\n",
            "Epoch 200/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9249\n",
            "Epoch 1/200\n",
            "38/38 [==============================] - 1s 2ms/step - loss: 4.4071 - accuracy: 0.0216\n",
            "Epoch 2/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.3529 - accuracy: 0.0340\n",
            "Epoch 3/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.2769 - accuracy: 0.0885\n",
            "Epoch 4/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.2097 - accuracy: 0.0799\n",
            "Epoch 5/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.2009 - accuracy: 0.0654\n",
            "Epoch 6/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.1930 - accuracy: 0.0469\n",
            "Epoch 7/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.9938 - accuracy: 0.1053\n",
            "Epoch 8/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.9700 - accuracy: 0.1257\n",
            "Epoch 9/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.9190 - accuracy: 0.1161\n",
            "Epoch 10/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.8569 - accuracy: 0.1080\n",
            "Epoch 11/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.7977 - accuracy: 0.1212\n",
            "Epoch 12/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.7275 - accuracy: 0.1086\n",
            "Epoch 13/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.6459 - accuracy: 0.1792\n",
            "Epoch 14/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.5940 - accuracy: 0.1348\n",
            "Epoch 15/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.6318 - accuracy: 0.1388\n",
            "Epoch 16/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.4785 - accuracy: 0.1720\n",
            "Epoch 17/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2653 - accuracy: 0.2319\n",
            "Epoch 18/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.4566 - accuracy: 0.1320\n",
            "Epoch 19/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.3701 - accuracy: 0.1673\n",
            "Epoch 20/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2440 - accuracy: 0.1924\n",
            "Epoch 21/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.3078 - accuracy: 0.2183\n",
            "Epoch 22/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2746 - accuracy: 0.1958\n",
            "Epoch 23/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1325 - accuracy: 0.2191\n",
            "Epoch 24/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0670 - accuracy: 0.2464\n",
            "Epoch 25/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0841 - accuracy: 0.2456\n",
            "Epoch 26/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8948 - accuracy: 0.2625\n",
            "Epoch 27/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9913 - accuracy: 0.2791\n",
            "Epoch 28/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8044 - accuracy: 0.3139\n",
            "Epoch 29/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4868 - accuracy: 0.3499\n",
            "Epoch 30/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6545 - accuracy: 0.3782\n",
            "Epoch 31/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.5647 - accuracy: 0.3134\n",
            "Epoch 32/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7148 - accuracy: 0.3456\n",
            "Epoch 33/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7012 - accuracy: 0.3273\n",
            "Epoch 34/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4617 - accuracy: 0.3844\n",
            "Epoch 35/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.3799 - accuracy: 0.4158\n",
            "Epoch 36/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.3879 - accuracy: 0.4580\n",
            "Epoch 37/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.3021 - accuracy: 0.4584\n",
            "Epoch 38/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.2920 - accuracy: 0.4231\n",
            "Epoch 39/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1587 - accuracy: 0.4703\n",
            "Epoch 40/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1656 - accuracy: 0.4400\n",
            "Epoch 41/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9244 - accuracy: 0.5498\n",
            "Epoch 42/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1041 - accuracy: 0.4804\n",
            "Epoch 43/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.0815 - accuracy: 0.5261\n",
            "Epoch 44/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.0396 - accuracy: 0.4800\n",
            "Epoch 45/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9267 - accuracy: 0.5036\n",
            "Epoch 46/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1046 - accuracy: 0.4457\n",
            "Epoch 47/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7437 - accuracy: 0.5638\n",
            "Epoch 48/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.0384 - accuracy: 0.5106\n",
            "Epoch 49/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.6478 - accuracy: 0.5991\n",
            "Epoch 50/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.0326 - accuracy: 0.4808\n",
            "Epoch 51/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7836 - accuracy: 0.5380\n",
            "Epoch 52/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.8261 - accuracy: 0.5077\n",
            "Epoch 53/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7921 - accuracy: 0.5965\n",
            "Epoch 54/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.8081 - accuracy: 0.5520\n",
            "Epoch 55/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5226 - accuracy: 0.5813\n",
            "Epoch 56/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3561 - accuracy: 0.6687\n",
            "Epoch 57/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4970 - accuracy: 0.6114\n",
            "Epoch 58/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3501 - accuracy: 0.6025\n",
            "Epoch 59/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2391 - accuracy: 0.6475\n",
            "Epoch 60/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3206 - accuracy: 0.5976\n",
            "Epoch 61/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3908 - accuracy: 0.5948\n",
            "Epoch 62/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3935 - accuracy: 0.6310\n",
            "Epoch 63/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3679 - accuracy: 0.6512\n",
            "Epoch 64/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3346 - accuracy: 0.6743\n",
            "Epoch 65/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3869 - accuracy: 0.6585\n",
            "Epoch 66/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5408 - accuracy: 0.5977\n",
            "Epoch 67/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2476 - accuracy: 0.6953\n",
            "Epoch 68/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1559 - accuracy: 0.6780\n",
            "Epoch 69/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1025 - accuracy: 0.6764\n",
            "Epoch 70/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2860 - accuracy: 0.6550\n",
            "Epoch 71/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9956 - accuracy: 0.7394\n",
            "Epoch 72/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1841 - accuracy: 0.7048\n",
            "Epoch 73/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1890 - accuracy: 0.6039\n",
            "Epoch 74/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1626 - accuracy: 0.6580\n",
            "Epoch 75/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0611 - accuracy: 0.7549\n",
            "Epoch 76/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0581 - accuracy: 0.7251\n",
            "Epoch 77/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1517 - accuracy: 0.6838\n",
            "Epoch 78/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2098 - accuracy: 0.6499\n",
            "Epoch 79/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0347 - accuracy: 0.7149\n",
            "Epoch 80/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2064 - accuracy: 0.6359\n",
            "Epoch 81/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9535 - accuracy: 0.7829\n",
            "Epoch 82/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0631 - accuracy: 0.6986\n",
            "Epoch 83/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.6779\n",
            "Epoch 84/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9101 - accuracy: 0.7500\n",
            "Epoch 85/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0706 - accuracy: 0.6827\n",
            "Epoch 86/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9655 - accuracy: 0.7396\n",
            "Epoch 87/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0909 - accuracy: 0.6953\n",
            "Epoch 88/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8746 - accuracy: 0.7419\n",
            "Epoch 89/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0918 - accuracy: 0.6930\n",
            "Epoch 90/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0082 - accuracy: 0.7153\n",
            "Epoch 91/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8466 - accuracy: 0.7740\n",
            "Epoch 92/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0854 - accuracy: 0.7120\n",
            "Epoch 93/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9185 - accuracy: 0.7354\n",
            "Epoch 94/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2675 - accuracy: 0.6230\n",
            "Epoch 95/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0558 - accuracy: 0.6795\n",
            "Epoch 96/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7871 - accuracy: 0.8075\n",
            "Epoch 97/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1432 - accuracy: 0.6574\n",
            "Epoch 98/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9377 - accuracy: 0.7255\n",
            "Epoch 99/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0931 - accuracy: 0.6923\n",
            "Epoch 100/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9656 - accuracy: 0.7202\n",
            "Epoch 101/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9037 - accuracy: 0.7559\n",
            "Epoch 102/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8868 - accuracy: 0.7582\n",
            "Epoch 103/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8508 - accuracy: 0.7588\n",
            "Epoch 104/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.7698\n",
            "Epoch 105/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0528 - accuracy: 0.7219\n",
            "Epoch 106/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9218 - accuracy: 0.7202\n",
            "Epoch 107/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7594 - accuracy: 0.8048\n",
            "Epoch 108/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0203 - accuracy: 0.7226\n",
            "Epoch 109/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.7780\n",
            "Epoch 110/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7803 - accuracy: 0.7813\n",
            "Epoch 111/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7505 - accuracy: 0.7853\n",
            "Epoch 112/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9532 - accuracy: 0.7345\n",
            "Epoch 113/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7955 - accuracy: 0.7850\n",
            "Epoch 114/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7761 - accuracy: 0.7739\n",
            "Epoch 115/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9334 - accuracy: 0.7303\n",
            "Epoch 116/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8812 - accuracy: 0.7300\n",
            "Epoch 117/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7078 - accuracy: 0.7986\n",
            "Epoch 118/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7157 - accuracy: 0.7575\n",
            "Epoch 119/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7956 - accuracy: 0.7957\n",
            "Epoch 120/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7325 - accuracy: 0.7930\n",
            "Epoch 121/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8245 - accuracy: 0.7515\n",
            "Epoch 122/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7977 - accuracy: 0.7759\n",
            "Epoch 123/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7726 - accuracy: 0.7681\n",
            "Epoch 124/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8392 - accuracy: 0.7221\n",
            "Epoch 125/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.7781\n",
            "Epoch 126/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8390 - accuracy: 0.7492\n",
            "Epoch 127/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.0136 - accuracy: 0.6836\n",
            "Epoch 128/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8541 - accuracy: 0.7432\n",
            "Epoch 129/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7322 - accuracy: 0.7578\n",
            "Epoch 130/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.8833\n",
            "Epoch 131/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7320 - accuracy: 0.7756\n",
            "Epoch 132/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7985 - accuracy: 0.7285\n",
            "Epoch 133/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9609 - accuracy: 0.6916\n",
            "Epoch 134/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.8268\n",
            "Epoch 135/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9110 - accuracy: 0.7133\n",
            "Epoch 136/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9371 - accuracy: 0.7556\n",
            "Epoch 137/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7173 - accuracy: 0.7940\n",
            "Epoch 138/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.8267\n",
            "Epoch 139/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.7869\n",
            "Epoch 140/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.7901\n",
            "Epoch 141/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7876 - accuracy: 0.7303\n",
            "Epoch 142/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8093 - accuracy: 0.7531\n",
            "Epoch 143/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.8446\n",
            "Epoch 144/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7753 - accuracy: 0.7912\n",
            "Epoch 145/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.7608\n",
            "Epoch 146/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7612 - accuracy: 0.7674\n",
            "Epoch 147/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9724 - accuracy: 0.6846\n",
            "Epoch 148/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9879 - accuracy: 0.7072\n",
            "Epoch 149/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7992 - accuracy: 0.7432\n",
            "Epoch 150/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7856 - accuracy: 0.7808\n",
            "Epoch 151/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7840 - accuracy: 0.7691\n",
            "Epoch 152/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.7856\n",
            "Epoch 153/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.8033\n",
            "Epoch 154/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9056 - accuracy: 0.7942\n",
            "Epoch 155/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7214 - accuracy: 0.7519\n",
            "Epoch 156/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7267 - accuracy: 0.7683\n",
            "Epoch 157/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.8269\n",
            "Epoch 158/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.8104\n",
            "Epoch 159/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.8451\n",
            "Epoch 160/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.7693\n",
            "Epoch 161/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.8053\n",
            "Epoch 162/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.8002\n",
            "Epoch 163/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.8036\n",
            "Epoch 164/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.7363\n",
            "Epoch 165/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.8091\n",
            "Epoch 166/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.7927\n",
            "Epoch 167/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.8172\n",
            "Epoch 168/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.8420\n",
            "Epoch 169/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.8288\n",
            "Epoch 170/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9077 - accuracy: 0.7469\n",
            "Epoch 171/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8330 - accuracy: 0.7761\n",
            "Epoch 172/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.8091\n",
            "Epoch 173/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.8340\n",
            "Epoch 174/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.8338\n",
            "Epoch 175/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.8092\n",
            "Epoch 176/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.8124\n",
            "Epoch 177/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.8280\n",
            "Epoch 178/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.8202\n",
            "Epoch 179/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.7930\n",
            "Epoch 180/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.8481\n",
            "Epoch 181/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8131 - accuracy: 0.7624\n",
            "Epoch 182/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.7938\n",
            "Epoch 183/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.7749\n",
            "Epoch 184/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.8021\n",
            "Epoch 185/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7900 - accuracy: 0.7517\n",
            "Epoch 186/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.8901\n",
            "Epoch 187/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8652\n",
            "Epoch 188/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.7958\n",
            "Epoch 189/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7568 - accuracy: 0.8126\n",
            "Epoch 190/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.7993\n",
            "Epoch 191/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.8140\n",
            "Epoch 192/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.8074\n",
            "Epoch 193/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.8207\n",
            "Epoch 194/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.8126\n",
            "Epoch 195/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7693 - accuracy: 0.7667\n",
            "Epoch 196/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.7434\n",
            "Epoch 197/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7589 - accuracy: 0.7926\n",
            "Epoch 198/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7711 - accuracy: 0.7604\n",
            "Epoch 199/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.7618\n",
            "Epoch 200/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.8165\n",
            "Epoch 1/200\n",
            "38/38 [==============================] - 1s 2ms/step - loss: 4.4079 - accuracy: 0.0220\n",
            "Epoch 2/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.3560 - accuracy: 0.0651\n",
            "Epoch 3/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.2963 - accuracy: 0.0686\n",
            "Epoch 4/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.2556 - accuracy: 0.0621\n",
            "Epoch 5/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.1102 - accuracy: 0.0802\n",
            "Epoch 6/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.1820 - accuracy: 0.0657\n",
            "Epoch 7/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.0298 - accuracy: 0.1214\n",
            "Epoch 8/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.0239 - accuracy: 0.0849\n",
            "Epoch 9/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.9055 - accuracy: 0.1025\n",
            "Epoch 10/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.8722 - accuracy: 0.1028\n",
            "Epoch 11/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.7890 - accuracy: 0.1126\n",
            "Epoch 12/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.7508 - accuracy: 0.1406\n",
            "Epoch 13/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.7740 - accuracy: 0.1365\n",
            "Epoch 14/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.6768 - accuracy: 0.1828\n",
            "Epoch 15/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.6729 - accuracy: 0.1615\n",
            "Epoch 16/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.7927 - accuracy: 0.1393\n",
            "Epoch 17/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.6382 - accuracy: 0.1574\n",
            "Epoch 18/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.6148 - accuracy: 0.1422\n",
            "Epoch 19/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.5206 - accuracy: 0.1567\n",
            "Epoch 20/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.5853 - accuracy: 0.1722\n",
            "Epoch 21/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.4688 - accuracy: 0.1738\n",
            "Epoch 22/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.3974 - accuracy: 0.2123\n",
            "Epoch 23/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.4378 - accuracy: 0.2102\n",
            "Epoch 24/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.3364 - accuracy: 0.2231\n",
            "Epoch 25/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.3622 - accuracy: 0.2321\n",
            "Epoch 26/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.4779 - accuracy: 0.2125\n",
            "Epoch 27/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.4254 - accuracy: 0.1842\n",
            "Epoch 28/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2489 - accuracy: 0.3003\n",
            "Epoch 29/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2590 - accuracy: 0.2499\n",
            "Epoch 30/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2171 - accuracy: 0.2453\n",
            "Epoch 31/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.3756 - accuracy: 0.2208\n",
            "Epoch 32/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.3261 - accuracy: 0.2143\n",
            "Epoch 33/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.5444 - accuracy: 0.1750\n",
            "Epoch 34/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1661 - accuracy: 0.2808\n",
            "Epoch 35/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2613 - accuracy: 0.2424\n",
            "Epoch 36/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2393 - accuracy: 0.2744\n",
            "Epoch 37/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0874 - accuracy: 0.2599\n",
            "Epoch 38/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1941 - accuracy: 0.2418\n",
            "Epoch 39/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0955 - accuracy: 0.3186\n",
            "Epoch 40/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2447 - accuracy: 0.2409\n",
            "Epoch 41/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.3269 - accuracy: 0.2298\n",
            "Epoch 42/200\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3.2527 - accuracy: 0.2515\n",
            "Epoch 43/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9869 - accuracy: 0.3360\n",
            "Epoch 44/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1914 - accuracy: 0.2833\n",
            "Epoch 45/200\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2.9789 - accuracy: 0.3001\n",
            "Epoch 46/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0916 - accuracy: 0.2943\n",
            "Epoch 47/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0977 - accuracy: 0.2750\n",
            "Epoch 48/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9385 - accuracy: 0.2996\n",
            "Epoch 49/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1485 - accuracy: 0.2426\n",
            "Epoch 50/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9044 - accuracy: 0.3132\n",
            "Epoch 51/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9960 - accuracy: 0.3081\n",
            "Epoch 52/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1203 - accuracy: 0.2294\n",
            "Epoch 53/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1357 - accuracy: 0.3123\n",
            "Epoch 54/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1856 - accuracy: 0.3099\n",
            "Epoch 55/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7631 - accuracy: 0.3498\n",
            "Epoch 56/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9608 - accuracy: 0.2922\n",
            "Epoch 57/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8897 - accuracy: 0.3547\n",
            "Epoch 58/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0234 - accuracy: 0.3080\n",
            "Epoch 59/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1468 - accuracy: 0.3012\n",
            "Epoch 60/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9805 - accuracy: 0.3202\n",
            "Epoch 61/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9760 - accuracy: 0.3116\n",
            "Epoch 62/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0975 - accuracy: 0.2551\n",
            "Epoch 63/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9661 - accuracy: 0.3056\n",
            "Epoch 64/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9144 - accuracy: 0.3374\n",
            "Epoch 65/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9348 - accuracy: 0.3018\n",
            "Epoch 66/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1246 - accuracy: 0.2793\n",
            "Epoch 67/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8803 - accuracy: 0.3256\n",
            "Epoch 68/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9706 - accuracy: 0.3298\n",
            "Epoch 69/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0796 - accuracy: 0.2900\n",
            "Epoch 70/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9340 - accuracy: 0.3371\n",
            "Epoch 71/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9647 - accuracy: 0.2704\n",
            "Epoch 72/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8591 - accuracy: 0.3347\n",
            "Epoch 73/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0287 - accuracy: 0.3114\n",
            "Epoch 74/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1250 - accuracy: 0.2862\n",
            "Epoch 75/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7851 - accuracy: 0.3765\n",
            "Epoch 76/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8817 - accuracy: 0.3268\n",
            "Epoch 77/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7042 - accuracy: 0.3918\n",
            "Epoch 78/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0778 - accuracy: 0.2680\n",
            "Epoch 79/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7819 - accuracy: 0.3479\n",
            "Epoch 80/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9452 - accuracy: 0.3450\n",
            "Epoch 81/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9137 - accuracy: 0.3042\n",
            "Epoch 82/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9288 - accuracy: 0.3299\n",
            "Epoch 83/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8405 - accuracy: 0.3293\n",
            "Epoch 84/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8889 - accuracy: 0.3164\n",
            "Epoch 85/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9042 - accuracy: 0.3117\n",
            "Epoch 86/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9016 - accuracy: 0.3357\n",
            "Epoch 87/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9155 - accuracy: 0.3532\n",
            "Epoch 88/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9101 - accuracy: 0.3330\n",
            "Epoch 89/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7491 - accuracy: 0.3514\n",
            "Epoch 90/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0143 - accuracy: 0.3032\n",
            "Epoch 91/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8136 - accuracy: 0.3590\n",
            "Epoch 92/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6807 - accuracy: 0.3574\n",
            "Epoch 93/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9671 - accuracy: 0.3099\n",
            "Epoch 94/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7164 - accuracy: 0.3536\n",
            "Epoch 95/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6482 - accuracy: 0.3559\n",
            "Epoch 96/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0116 - accuracy: 0.2943\n",
            "Epoch 97/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9975 - accuracy: 0.3319\n",
            "Epoch 98/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7135 - accuracy: 0.3441\n",
            "Epoch 99/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8901 - accuracy: 0.3135\n",
            "Epoch 100/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8184 - accuracy: 0.2971\n",
            "Epoch 101/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1050 - accuracy: 0.2919\n",
            "Epoch 102/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8193 - accuracy: 0.3166\n",
            "Epoch 103/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8663 - accuracy: 0.3116\n",
            "Epoch 104/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7562 - accuracy: 0.3660\n",
            "Epoch 105/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9316 - accuracy: 0.3103\n",
            "Epoch 106/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9767 - accuracy: 0.2780\n",
            "Epoch 107/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8326 - accuracy: 0.3399\n",
            "Epoch 108/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6887 - accuracy: 0.3773\n",
            "Epoch 109/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8515 - accuracy: 0.3288\n",
            "Epoch 110/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8997 - accuracy: 0.3157\n",
            "Epoch 111/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8220 - accuracy: 0.3427\n",
            "Epoch 112/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7367 - accuracy: 0.3591\n",
            "Epoch 113/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7123 - accuracy: 0.3591\n",
            "Epoch 114/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8437 - accuracy: 0.3230\n",
            "Epoch 115/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0546 - accuracy: 0.2973\n",
            "Epoch 116/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9515 - accuracy: 0.3264\n",
            "Epoch 117/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9192 - accuracy: 0.3130\n",
            "Epoch 118/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8158 - accuracy: 0.3245\n",
            "Epoch 119/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8394 - accuracy: 0.3080\n",
            "Epoch 120/200\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2.8360 - accuracy: 0.3289\n",
            "Epoch 121/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8076 - accuracy: 0.3124\n",
            "Epoch 122/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.5722 - accuracy: 0.3811\n",
            "Epoch 123/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9208 - accuracy: 0.3016\n",
            "Epoch 124/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8065 - accuracy: 0.3548\n",
            "Epoch 125/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9252 - accuracy: 0.3225\n",
            "Epoch 126/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8374 - accuracy: 0.3221\n",
            "Epoch 127/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8809 - accuracy: 0.3416\n",
            "Epoch 128/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8215 - accuracy: 0.3313\n",
            "Epoch 129/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8558 - accuracy: 0.3409\n",
            "Epoch 130/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8479 - accuracy: 0.3491\n",
            "Epoch 131/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.5811 - accuracy: 0.4102\n",
            "Epoch 132/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6420 - accuracy: 0.3761\n",
            "Epoch 133/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.5819 - accuracy: 0.3996\n",
            "Epoch 134/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8149 - accuracy: 0.3213\n",
            "Epoch 135/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6670 - accuracy: 0.3572\n",
            "Epoch 136/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8094 - accuracy: 0.3432\n",
            "Epoch 137/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7009 - accuracy: 0.3907\n",
            "Epoch 138/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8375 - accuracy: 0.3196\n",
            "Epoch 139/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7841 - accuracy: 0.3627\n",
            "Epoch 140/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8090 - accuracy: 0.3670\n",
            "Epoch 141/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8157 - accuracy: 0.3204\n",
            "Epoch 142/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7253 - accuracy: 0.3909\n",
            "Epoch 143/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8142 - accuracy: 0.3640\n",
            "Epoch 144/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7027 - accuracy: 0.3511\n",
            "Epoch 145/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9557 - accuracy: 0.2626\n",
            "Epoch 146/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7549 - accuracy: 0.3452\n",
            "Epoch 147/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1078 - accuracy: 0.2776\n",
            "Epoch 148/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6674 - accuracy: 0.3868\n",
            "Epoch 149/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6640 - accuracy: 0.3398\n",
            "Epoch 150/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8874 - accuracy: 0.3304\n",
            "Epoch 151/200\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2.9839 - accuracy: 0.2966\n",
            "Epoch 152/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6970 - accuracy: 0.3736\n",
            "Epoch 153/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9786 - accuracy: 0.2970\n",
            "Epoch 154/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7375 - accuracy: 0.3562\n",
            "Epoch 155/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6677 - accuracy: 0.3529\n",
            "Epoch 156/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9870 - accuracy: 0.2738\n",
            "Epoch 157/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6645 - accuracy: 0.3770\n",
            "Epoch 158/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7035 - accuracy: 0.3574\n",
            "Epoch 159/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8138 - accuracy: 0.3320\n",
            "Epoch 160/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9419 - accuracy: 0.3351\n",
            "Epoch 161/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.5967 - accuracy: 0.3918\n",
            "Epoch 162/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9111 - accuracy: 0.3171\n",
            "Epoch 163/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9272 - accuracy: 0.3084\n",
            "Epoch 164/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7769 - accuracy: 0.3969\n",
            "Epoch 165/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9351 - accuracy: 0.3069\n",
            "Epoch 166/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8150 - accuracy: 0.3231\n",
            "Epoch 167/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9652 - accuracy: 0.3282\n",
            "Epoch 168/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7892 - accuracy: 0.3393\n",
            "Epoch 169/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7685 - accuracy: 0.3582\n",
            "Epoch 170/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7017 - accuracy: 0.3846\n",
            "Epoch 171/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8706 - accuracy: 0.3133\n",
            "Epoch 172/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9563 - accuracy: 0.2940\n",
            "Epoch 173/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7953 - accuracy: 0.3192\n",
            "Epoch 174/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8945 - accuracy: 0.3271\n",
            "Epoch 175/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6292 - accuracy: 0.3921\n",
            "Epoch 176/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7626 - accuracy: 0.3400\n",
            "Epoch 177/200\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3.0002 - accuracy: 0.2938\n",
            "Epoch 178/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7314 - accuracy: 0.3629\n",
            "Epoch 179/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8041 - accuracy: 0.3388\n",
            "Epoch 180/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8488 - accuracy: 0.3221\n",
            "Epoch 181/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8230 - accuracy: 0.3418\n",
            "Epoch 182/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8650 - accuracy: 0.3125\n",
            "Epoch 183/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8017 - accuracy: 0.3374\n",
            "Epoch 184/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7834 - accuracy: 0.3492\n",
            "Epoch 185/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8050 - accuracy: 0.3262\n",
            "Epoch 186/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7385 - accuracy: 0.3629\n",
            "Epoch 187/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8332 - accuracy: 0.3240\n",
            "Epoch 188/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7764 - accuracy: 0.3174\n",
            "Epoch 189/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7170 - accuracy: 0.3735\n",
            "Epoch 190/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8898 - accuracy: 0.3282\n",
            "Epoch 191/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7997 - accuracy: 0.3584\n",
            "Epoch 192/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6915 - accuracy: 0.3730\n",
            "Epoch 193/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.8644 - accuracy: 0.3081\n",
            "Epoch 194/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9870 - accuracy: 0.2906\n",
            "Epoch 195/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9527 - accuracy: 0.3079\n",
            "Epoch 196/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7868 - accuracy: 0.3323\n",
            "Epoch 197/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9506 - accuracy: 0.3147\n",
            "Epoch 198/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7514 - accuracy: 0.3633\n",
            "Epoch 199/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7171 - accuracy: 0.3666\n",
            "Epoch 200/200\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9718 - accuracy: 0.2822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2tHRHVEJpgv"
      },
      "source": [
        "def reply(input, method):\n",
        "  if method == 'unigram':\n",
        "    class_pred = classes[np.argmax(unigram_model.predict(unigram_vec.transform([input]))[0])]\n",
        "  elif method == 'bigram':\n",
        "    class_pred = classes[np.argmax(bigram_model.predict(bigram_vec.transform([input]))[0])]\n",
        "  elif method == 'trigram':\n",
        "    class_pred = classes[np.argmax(trigram_model.predict(trigram_vec.transform([input]))[0])]\n",
        "  \n",
        "  for intent in intents['intents']:\n",
        "    if class_pred == intent['tag']:\n",
        "      return {'reply': (random.choice(intent['responses'])),\n",
        "              'pred_intent': class_pred}\n",
        "      \n",
        "\n",
        "#continue to next line if line is too long\n",
        "def next_line(string, line_length = 75):\n",
        "  if len(string) == line_length:\n",
        "    return string\n",
        "  length = 0\n",
        "  lines = []\n",
        "  current_line = ''\n",
        "  for word in string.split(' '):\n",
        "    current_line += word + ' '\n",
        "    length += len(word)\n",
        "    if length >= line_length:\n",
        "      length = 0\n",
        "      lines.append(current_line)\n",
        "      current_line = ''\n",
        "  lines.append(current_line)\n",
        "  return '\\n'.join(lines) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3mb4R9mGo1G"
      },
      "source": [
        "## Chatbot Performance Assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stDj3h8Y7ySL"
      },
      "source": [
        "X_test = pd.read_csv('https://raw.githubusercontent.com/nschandr/CSC466-Group-Project/main/testdata.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl4wJ5rHIRW2"
      },
      "source": [
        "def get_accuracy(X_test, method, show_conversation=False):\n",
        "  n_correct = 0\n",
        "  n = len(X_test)\n",
        "  for i in range(n):\n",
        "    input = X_test['user_input'][i]\n",
        "    actual_intent = X_test['tag'][i]\n",
        "\n",
        "    reply_dict = reply(input, method)\n",
        "    reply_str = reply_dict['reply']\n",
        "    pred_intent = reply_dict['pred_intent']\n",
        "    \n",
        "    if show_conversation:\n",
        "      print('You: ' + input)\n",
        "      print('CS Bot: ' + next_line(reply_str))\n",
        "      print('Actual intent: {}, Predicted Intent: {}\\n'.format(actual_intent, pred_intent))\n",
        "\n",
        "    if pred_intent == actual_intent:\n",
        "      n_correct += 1\n",
        "\n",
        "  accuracy = (n_correct / n) * 100\n",
        "  print('Accuracy: {}%'.format(accuracy))\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxNgFkE5bZwY",
        "outputId": "c190c8d9-fe1d-4cf8-f6e0-f4226632810b"
      },
      "source": [
        "unigram_accuracy = get_accuracy(X_test, 'unigram', show_conversation=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You: Greetings\n",
            "CS Bot: How are you? \n",
            "Actual intent: greeting, Predicted Intent: greeting\n",
            "\n",
            "You: Good\n",
            "CS Bot: Great! How can I help you? \n",
            "Actual intent: doing_good, Predicted Intent: doing_good\n",
            "\n",
            "You: What can you do?\n",
            "CS Bot: Based on some of your degree progress information, I can help suggest some Computer Science \n",
            "courses for you to take this coming quarter. Or if you need to know the prerequisites for a CSC \n",
            "course, just say the course number. \n",
            "Actual intent: options, Predicted Intent: options\n",
            "\n",
            "You: How do we begin?\n",
            "CS Bot: To get started, please give me your class standing and what quarter you need suggestions for. \n",
            "\n",
            "Actual intent: info_gain, Predicted Intent: info_gain\n",
            "\n",
            "You: Senior Fall quarter\n",
            "CS Bot: It is suggested that you take one of the approved technical electives \n",
            "Actual intent: senior_fall, Predicted Intent: senior_fall\n",
            "\n",
            "You: What technical electives are there?\n",
            "CS Bot: The suggested technical electives depend on your concentration and your interests (Ex. \n",
            "Software engineering, game design, etc.). What is your concentration? If it is the general \n",
            "curriculum, also specify some of your interests. \n",
            "Actual intent: technical_electives, Predicted Intent: technical_electives\n",
            "\n",
            "You: I'm into gaming development. What game development electives can I take?\n",
            "CS Bot: The following technical electives are required as a part of the game development concentration: \n",
            "COMS 404, CSC 371, 377, 378, ISLA 340. 4 more units of any of the following are also required: \n",
            "ART 182, 183, 376, 384, CSC 309, 471, 473, 474, 476, 478, 480, ISLA 240, 341, 387, 411, 412 \n",
            "Actual intent: game_dev, Predicted Intent: game_dev\n",
            "\n",
            "You: What are the prerequisites for these classes?\n",
            "CS Bot: Just type in the CSC followed by the course number and I'll let you know what the prereqs are \n",
            "\n",
            "Actual intent: prereqs, Predicted Intent: prereqs\n",
            "\n",
            "You: CSC 480?\n",
            "CS Bot: Prequisite requirements for this course include: CSC 102 and 103 or CSC 202 and Junior Standing \n",
            "\n",
            "Actual intent: 101/103_202js_prereq, Predicted Intent: 102/103_202js_prereq\n",
            "\n",
            "You: CSC 225?\n",
            "CS Bot: Prerequisite requirements for this course include: CSC 202 \n",
            "Actual intent: csc202_prereq, Predicted Intent: csc202_prereq\n",
            "\n",
            "You: CSC 371?\n",
            "CS Bot: Prequisite requirements for this course include: CSC 102 and 103 or CSC 202 and Junior Standing \n",
            "\n",
            "Actual intent: 101/103_202js_prereq, Predicted Intent: 102/103_202js_prereq\n",
            "\n",
            "You: CSC 321?\n",
            "CS Bot: Prequisite requirements for this course include: CSC 357 \n",
            "Actual intent: csc357_prereq, Predicted Intent: csc357_prereq\n",
            "\n",
            "You: gfsgfds\n",
            "CS Bot: Sorry, I couldn't understand that \n",
            "Actual intent: noanswer, Predicted Intent: noanswer\n",
            "\n",
            "You: I'm done\n",
            "CS Bot: Can you please provide a bit more information? \n",
            "Actual intent: complete, Predicted Intent: noanswer\n",
            "\n",
            "You: Thank you for the help!\n",
            "CS Bot: Absolutely \n",
            "Actual intent: thanks, Predicted Intent: thanks\n",
            "\n",
            "You: Bye\n",
            "CS Bot: Bye \n",
            "Actual intent: goodbye, Predicted Intent: goodbye\n",
            "\n",
            "Accuracy: 81.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dypqc3kYdY8b",
        "outputId": "a2fbffc9-a8e3-4dcd-db73-2a27ada3cf9d"
      },
      "source": [
        "bigram_accuracy = get_accuracy(X_test, 'bigram')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 50.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEuT5bXheKLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84965f0d-d3b7-4ca2-9de1-4bd4ff7074e9"
      },
      "source": [
        "trigram_accuracy = get_accuracy(X_test, 'trigram')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 18.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "cVJ8w1RKldW9",
        "outputId": "7c9199ea-e5e4-424d-c59d-45d2e33c2494"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gram</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>unigram</td>\n",
              "      <td>81.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bigram</td>\n",
              "      <td>50.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>trigram</td>\n",
              "      <td>18.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      gram  accuracy\n",
              "0  unigram     81.25\n",
              "1   bigram     50.00\n",
              "2  trigram     18.75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "v5SCmVC4k4jo",
        "outputId": "8912efe2-7f50-4d54-c942-4abf5f8358b3"
      },
      "source": [
        "results = pd.DataFrame({'gram': ['Unigram', 'Bigram', 'Trigram'],\n",
        "                        'accuracy': [unigram_accuracy, bigram_accuracy, trigram_accuracy]})\n",
        "\n",
        "dims = (10, 8)\n",
        "fig, ax = plt.subplots(figsize=dims)\n",
        "plot = sns.barplot(ax=ax, x=\"gram\", y=\"accuracy\", data=results)\n",
        "ax.set_title('Model Performance Assessment Results')\n",
        "ax.set_xlabel('Training Set Approach')\n",
        "ax.set_ylabel('Accuracy (%)')\n",
        "fig = plot.get_figure()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-b9309b280422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_fig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'466projresults.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no attribute 'save_fig'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xahUn6-0cz6n"
      },
      "source": [
        "gram = 'unigram'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKDB-pNvKzCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "1324da2b-7ec0-4942-dd7e-430ad0bfe639"
      },
      "source": [
        "#@title Say hello to... CS Bot!\n",
        "print('CS Bot Activated' + '\\n' + 'Type \"quit\" to exit' + '\\n')\n",
        "while True:\n",
        "  pattern = input('You: ')\n",
        "  print('')\n",
        "  if pattern.lower() == 'quit':\n",
        "    print('CS Bot Terminated')\n",
        "    break\n",
        "  reply_str = reply(pattern, gram)['reply']\n",
        "  \n",
        "  print('CS Bot: ' + next_line(reply_str) + '\\n')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CS Bot Activated\n",
            "Type \"quit\" to exit\n",
            "\n",
            "You: hello\n",
            "\n",
            "CS Bot: How are you? \n",
            "\n",
            "You: good\n",
            "\n",
            "CS Bot: Great! How can I help you? \n",
            "\n",
            "You: I need help deciding on what CSC classes to take next quarter\n",
            "\n",
            "CS Bot: Sure, just let me know what year/class standing you'll be and what quarter you need the recommendation \n",
            "for. \n",
            "\n",
            "You: I am a Senior and I need help for Fall\n",
            "\n",
            "CS Bot: It is suggested that you take one of the approved technical electives \n",
            "\n",
            "You: What are the technical electives?\n",
            "\n",
            "CS Bot: The suggested technical electives depend on your concentration and your interests (Ex. \n",
            "Software engineering, game design, etc.). What is your concentration? If it is the general \n",
            "curriculum, also specify some of your interests. \n",
            "\n",
            "You: My concentration is Game development\n",
            "\n",
            "CS Bot: The following technical electives are required as a part of the game development concentration: \n",
            "COMS 404, CSC 371, 377, 378, ISLA 340. 4 more units of any of the following are also required: \n",
            "ART 182, 183, 376, 384, CSC 309, 471, 473, 474, 476, 478, 480, ISLA 240, 341, 387, 411, 412 \n",
            "\n",
            "You: Can you tell me what the prereqs are for some classes?\n",
            "\n",
            "CS Bot: Just type in the CSC followed by the course number and I'll let you know what the prereqs are \n",
            "\n",
            "\n",
            "You: CSC 371\n",
            "\n",
            "CS Bot: Prequisite requirements for this course include: CSC 102 and 103 or CSC 202 and Junior Standing \n",
            "\n",
            "\n",
            "You: Thanks\n",
            "\n",
            "CS Bot: Happy to help \n",
            "\n",
            "You: bye\n",
            "\n",
            "CS Bot: Have a nice day! \n",
            "\n",
            "You: quit\n",
            "\n",
            "CS Bot Terminated\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}